{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXcxk_-VQnbo"
      },
      "source": [
        "**STEP 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6FP2I5GInbsK"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByvhAQxvQz9W"
      },
      "source": [
        "STEP 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz_oslrvo-Sf",
        "outputId": "248ebd61-8be8-4ced-a66b-ff94dff1fcf7"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/diabetes.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/content/diabetes.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Check the available columns in your dataset\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(data.columns)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/diabetes.csv'"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv('/content/diabetes.csv')\n",
        "\n",
        "# Check the available columns in your dataset\n",
        "print(data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lmahG3KaNi8R"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Split data into features and target\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X = \u001b[43mdata\u001b[49m[[\u001b[33m'\u001b[39m\u001b[33mAge\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGlucose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mInsulin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mBMI\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m      3\u001b[39m y = data[\u001b[33m'\u001b[39m\u001b[33mOutcome\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "# Split data into features and target\n",
        "X = data[['Age', 'Glucose', 'Insulin', 'BMI']]\n",
        "y = data['Outcome']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9NUUxnynruqL"
      },
      "outputs": [],
      "source": [
        "# Assuming `X_train` is your training data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Train your models with `X_train_scaled` and then save both the models and the scaler\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC1vk5IQpG3W"
      },
      "source": [
        "STEP 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gkTLMsVIpIFJ"
      },
      "outputs": [],
      "source": [
        "# Train Naive Bayes model\n",
        "naive_bayes_model = GaussianNB()\n",
        "naive_bayes_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict with Naive Bayes\n",
        "y_pred_nb = naive_bayes_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaqpFfC9pKRX"
      },
      "source": [
        "STEP 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XpTPD5kKpLWH"
      },
      "outputs": [],
      "source": [
        "# Train Perceptron model\n",
        "perceptron_model = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
        "perceptron_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict with Perceptron\n",
        "y_pred_perceptron = perceptron_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRNn9xMQwYxw"
      },
      "source": [
        "Custom perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqF9UymQnl_u"
      },
      "source": [
        "The CustomPerceptron class models a simple perceptron, a linear classifier that adjusts its weights iteratively based on misclassified samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tUQiBj0hvSuo"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomPerceptron:\n",
        "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
        "        #learning_rate: Controls how much the weights are updated after each misclassification.\n",
        "        self.learning_rate = learning_rate\n",
        "        #n_iters: The number of iterations (epochs) to train the model.\n",
        "        self.n_iters = n_iters\n",
        "        #weights: An array to store the weights corresponding to each feature in the dataset. Initialized\n",
        "        self.weights = None\n",
        "        #bias: An intercept term added to the linear function, also initialized during training.\n",
        "        self.bias = None\n",
        "\n",
        "\n",
        "#X: Feature matrix of shape (n_samples, n_features), where n_samples is the number of data points and n_features is the number of features.\n",
        "#y: Target labels, assumed to be binary (0 and 1).\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        #self.weights as a zero array of size equal to the number of features.\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Convert labels to -1 and 1 if they are 0 and 1, for Perceptron calculation\n",
        "        y_ = np.where(y <= 0, -1, 1)\n",
        "\n",
        "        # Training loop\n",
        "        #linear_output: Computes the weighted sum of inputs (X) and weights, plus the bias:z=wTx+b\n",
        "        # y_predicted:Applies the sign function to classify the sample\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = np.sign(linear_output)\n",
        "\n",
        "                # Update weights and bias if prediction is incorrect\n",
        "                #Update Rule: If the prediction (y_predicted) is incorrect, update the weights and bias:\n",
        "                #w=w+ηy\n",
        "                #b=b+ηy\n",
        "\n",
        "                if y_predicted != y_[idx]:\n",
        "                    self.weights += self.learning_rate * y_[idx] * x_i\n",
        "                    self.bias += self.learning_rate * y_[idx]\n",
        "\n",
        "#Computes the linear output for the input features\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        #Applies the sign function to classify the data.\n",
        "        y_predicted = np.sign(linear_output)\n",
        "        #Converts the outputs back to binary labels (0 and 1).\n",
        "        return np.where(y_predicted <= 0, 0, 1)\n",
        "\n",
        "# Initialize and train the custom Perceptron\n",
        "#Fits the model on the training dataset (X_train, y_train)\n",
        "custom_perceptron_model = CustomPerceptron(learning_rate=0.3, n_iters=500)\n",
        "custom_perceptron_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "# Predicts the labels for the test dataset (X_test).\n",
        "y_pred_custom_perceptron = custom_perceptron_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO9TqFptpN4Y"
      },
      "source": [
        "STEP 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0pCrpdOEpPDY"
      },
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    return {\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred, average='weighted'),\n",
        "        'Recall': recall_score(y_true, y_pred, average='weighted'),\n",
        "        'F1 Score': f1_score(y_true, y_pred, average='weighted')\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDMKAgtmNasy",
        "outputId": "16528c93-2769-464b-b74f-6e19c1f23be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Metrics: {'Accuracy': 0.7467532467532467, 'Precision': 0.7457671957671957, 'Recall': 0.7467532467532467, 'F1 Score': 0.7462278627738957}\n",
            "Perceptron Metrics: {'Accuracy': 0.6363636363636364, 'Precision': 0.6363636363636364, 'Recall': 0.6363636363636364, 'F1 Score': 0.6363636363636364}\n",
            "Custom Perceptron Metrics: {'Accuracy': 0.7532467532467533, 'Precision': 0.7475563504054762, 'Recall': 0.7532467532467533, 'F1 Score': 0.743401841868823}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate Naive Bayes\n",
        "nb_metrics = evaluate_model(y_test, y_pred_nb)\n",
        "print(\"Naive Bayes Metrics:\", nb_metrics)\n",
        "\n",
        "# Evaluate Perceptron\n",
        "perceptron_metrics = evaluate_model(y_test, y_pred_perceptron)\n",
        "print(\"Perceptron Metrics:\", perceptron_metrics)\n",
        "\n",
        "# Evaluate Custom made Perceptron\n",
        "custom_perceptron_metrics = evaluate_model(y_test, y_pred_custom_perceptron)\n",
        "print(\"Custom Perceptron Metrics:\", custom_perceptron_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX0YitajVhxw"
      },
      "source": [
        "**Analysis:**\n",
        "\n",
        "*Naive Bayes:*\n",
        "\n",
        "Strengths: Higher accuracy, precision, and recall indicate good performance, particularly in datasets with well-separated classes or features with strong independence.\n",
        "\n",
        "Weaknesses: May struggle if feature independence assumptions are violated or if features are heavily correlated.\n",
        "\n",
        "*Perceptron:*\n",
        "\n",
        "Strengths: Simplicity and computational efficiency make it useful for linearly separable datasets.\n",
        "\n",
        "Weaknesses: Lower performance metrics suggest potential struggles with convergence or non-linear decision boundaries.\n",
        "\n",
        "**Recommendation:**\n",
        "\n",
        "Use Naive Bayes if the dataset aligns well with its assumptions and speed is a priority.\n",
        "Consider Custom Perceptron for better generalization on diverse datasets, especially if it includes enhancements for non-linearity.\n",
        "Investigate further modifications or alternative models like Support Vector Machines (SVMs) or neural networks if neither suffices for the dataset's complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gayYwOnpRpX"
      },
      "source": [
        "STEP 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "GWnqwiRipTv2",
        "outputId": "c1bf00b1-b67d-42ce-9cd9-6e4d9f8d3701"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_fe60abcc-661a-4393-9c15-c683e639ac50\", \"naive_bayes_model.pkl\", 706)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_3bdb8910-e412-46e2-9f55-d87d8b2ed2c6\", \"perceptron_model.pkl\", 976)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_eb94ae91-7f84-45b9-b140-21585f724261\", \"custom_perceptron_model.pkl\", 305)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Save models\n",
        "with open('naive_bayes_model.pkl', 'wb') as f:\n",
        "    pickle.dump(naive_bayes_model, f)\n",
        "\n",
        "with open('perceptron_model.pkl', 'wb') as f:\n",
        "    pickle.dump(perceptron_model, f)\n",
        "\n",
        "with open('custom_perceptron_model.pkl', 'wb') as f:\n",
        "    pickle.dump(custom_perceptron_model, f)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Downloading the Naïve Bayes model\n",
        "files.download('naive_bayes_model.pkl')\n",
        "\n",
        "# Downloading the Perceptron model\n",
        "files.download('perceptron_model.pkl')\n",
        "\n",
        "# Downloading the Custom Perceptron model\n",
        "files.download('custom_perceptron_model.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS9Us4q4qbZ-"
      },
      "source": [
        "STEP 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VHHIlLpqckd",
        "outputId": "60509396-44a4-4af9-d913-337b9bba496b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Cross-Validation Scores: 0.7552754435107376\n",
            "Perceptron Cross-Validation Scores: 0.5480943892708598\n"
          ]
        }
      ],
      "source": [
        "# K-Fold Cross-validation for Naive Bayes\n",
        "nb_cv_scores = cross_val_score(naive_bayes_model, X, y, cv=5)\n",
        "print(\"Naive Bayes Cross-Validation Scores:\", nb_cv_scores.mean())\n",
        "\n",
        "# K-Fold Cross-validation for Perceptron\n",
        "perceptron_cv_scores = cross_val_score(perceptron_model, X, y, cv=5)\n",
        "print(\"Perceptron Cross-Validation Scores:\", perceptron_cv_scores.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esf3MDfB0LPi"
      },
      "source": [
        "STEP 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iTXoH7NB1PfB"
      },
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    return {\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred, average='weighted'),\n",
        "        'Recall': recall_score(y_true, y_pred, average='weighted'),\n",
        "        'F1 Score': f1_score(y_true, y_pred, average='weighted')\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NebCakrlNM8v",
        "outputId": "215424b3-9722-4439-d79c-fad95832df3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Metrics k-fold: {'Accuracy': 0.7467532467532467, 'Precision': 0.7457671957671957, 'Recall': 0.7467532467532467, 'F1 Score': 0.7462278627738957}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Naive Bayes\n",
        "\n",
        "# Predicting on the test set using the Naive Bayes model\n",
        "nb_predictions = naive_bayes_model.predict(X_test)\n",
        "# Evaluating the predictions against the actuals\n",
        "nb_metrics_k_fold = evaluate_model(y_test, nb_predictions)\n",
        "print(\"Naive Bayes Metrics k-fold:\", nb_metrics_k_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LUfP0ASNNAF",
        "outputId": "d43ea740-81aa-47a8-befa-0c6db984558e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perceptron Metrics k-fold: {'Accuracy': 0.6363636363636364, 'Precision': 0.6363636363636364, 'Recall': 0.6363636363636364, 'F1 Score': 0.6363636363636364}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Perceptron\n",
        "\n",
        "# Predicting on the test set using the Perceptron model\n",
        "perceptron_predictions = perceptron_model.predict(X_test)\n",
        "# Evaluating the predictions against the actuals\n",
        "perceptron_metrics_k_fold = evaluate_model(y_test, perceptron_predictions)\n",
        "print(\"Perceptron Metrics k-fold:\", perceptron_metrics_k_fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PIEOg__l3lM1"
      },
      "outputs": [],
      "source": [
        "# Initialize models\n",
        "naive_bayes_model = GaussianNB()\n",
        "perceptron_model = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
        "\n",
        "# Define scoring metrics\n",
        "scoring_metrics = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YlrhXosbNAiN"
      },
      "outputs": [],
      "source": [
        "# Function to perform cross-validation and print results\n",
        "def evaluate_model(model, model_name):\n",
        "    results = {}\n",
        "    for metric in scoring_metrics:\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=metric)  # 5-fold cross-validation\n",
        "        results[metric] = {\n",
        "            'mean': cv_scores.mean(),\n",
        "            'std': cv_scores.std()\n",
        "        }\n",
        "    print(f\"Model: {model_name}\")\n",
        "    for metric, scores in results.items():\n",
        "        print(f\"{metric.capitalize()}: Mean = {scores['mean']:.4f}, Std = {scores['std']:.4f}\")\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOi370MxNEbW",
        "outputId": "8fbe4ee5-625f-4dd9-d77b-629488b33415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Naive Bayes\n",
            "Accuracy: Mean = 0.7574, Std = 0.0260\n",
            "Precision_weighted: Mean = 0.7526, Std = 0.0281\n",
            "Recall_weighted: Mean = 0.7574, Std = 0.0260\n",
            "F1_weighted: Mean = 0.7490, Std = 0.0244\n",
            "--------------------\n",
            "Model: Perceptron\n",
            "Accuracy: Mean = 0.7361, Std = 0.0324\n",
            "Precision_weighted: Mean = 0.7406, Std = 0.0326\n",
            "Recall_weighted: Mean = 0.7361, Std = 0.0324\n",
            "F1_weighted: Mean = 0.7374, Std = 0.0321\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "# Evaluate models\n",
        "evaluate_model(naive_bayes_model, 'Naive Bayes')\n",
        "evaluate_model(perceptron_model, 'Perceptron')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
